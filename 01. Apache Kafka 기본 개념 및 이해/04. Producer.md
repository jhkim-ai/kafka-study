b# 04. Producer

## 1. Apache Kafka Clients

> `Kafka`의 `Client`에는 `Producer`와 `Consumer`가 있다

### 1) Producer, Consumer, Consumer Group

- `Producer` : 메시지를 생산(Producer)하여 Kafka의 Topic으로 전송하는 Application
- `Consumer` : Topic의 메시지를 가져와(Consumer) 사용하는 Application
- `Consumer Group` : Topic의 메시지를 사용하기 위해 협력하는 Consumer들의 집함
- 하나의 `Consumer`는 하나의 `Consumer Group`에 포함되며, `Consumer Group`내의 `Consumer`들은 협력하여 Topic의 메시지를 병렬 처리

### 2) Producer와 Consumer의 기본 동장 방식

![Producer & Consumer 기본 동작](../img/part1/04_01_Producer와Consumer_기본동작.PNG "Producer & Consumer 기본 동작")

- Producer와 Consumer는 서로 알지 못함
- Producer와 Consumer는 각각 고유의 속도로 Commit Log에 Write/Read 수행
- 다른 Consumer Group에 속한 Consumer 들은 서로 관련 없으며, Commit Log에 있는 Event(Message)를 동시에 다른 위치에서 Read할 수 있음

</br>

---

</br>

## 2. Record(Message) 구조

> Message == Record == Event == Data

<br/>

![Record 구조](../img/part1/04_02_Recode구조.PNG "Record 구조")

- Message 는 `Header`, `Key`, `Value` 구조를 가짐
- `Header`는 Metadata(Topic, Partition, Timestamp, etc)를 가짐
- `Key`, `value`는 비즈니스 데이터를 가짐
  - `Avro`, `JSON`, `String` 등 다양한 형태로 가능

</br>

---

</br>

## 3. Kafka는 Record(data)를 Byte Array로 저장

![ByteArray로 저장](../img/part1/04_03_ByteArray저장.PNG "ByteArray로 저장")

- `Producer`는 `JSON`, `String`, `Avro`, `Protobuf` 등의 데이터를 `Serialization(직렬화)`하여 Byte Array로 전환(저장)
- `Consumer`는 Byte Array를 `Deserialization(역직렬화)`하여 `JSON`, `String`, `Avro`, `Protobuf` 등의 데이터로 전환하여 사용

</br>

---

</br>

## 4. Producing to Kafka

</br>

![Producer 작동 과정](../img/part1/04_04_Producer작동과정.PNG "Producer 작동 과정")

[Producer의 작동 과정]

1. Producer가 Record(Message) 생성
   - 개발자 입장에서, Producer에서 `send()`메서드만 호출하면 뒤의 과정들은 자동으로 진행하여 `Kafka`로 전송
   - 실제로 메시지 전송을 관여하는 객체는 `Sender`와 `RecordAccumluator`
2. `send()`메서드로부터 `Kafka Cluster`에서 Topic 관련 최신 `Metadata`를 `Fetch`한다.
   - `send()` 메서드는 **`비동기`**
   - `waitOnMetadata()` 메서드를 호출하여 최신 `Metadata`를 `Fetch`한 뒤 `ProducerMetadata` 상태를 갱신
3. Record의 Serialization 진행
4. Partitioner에 의해 어떤 Partition으로 갈지 정해짐
5. 필요에 따라 압축(Compress) 진행
6. `Buffer` 역할을 하는 `RecordAccumulator 객체`(Accumulator)에 Batch 형태로 메시지를 저장한다(모은다).

   - Record마다 Broker로 전달하는 것은 **`Network I/O`의 `오버헤드`** 발생
   - **Network 비용을 줄이기 위해** `Batch` 형태의 묶음으로 저장

   | 옵션                      | 설명                                                                                                                                                               |
   | ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
   | batch.size (default 16kb) | size를 정의 하여 메세지의 용량이 size에 도달 할 때 까지 기다렸다가 보낸다.                                                                                         |
   | linger.ms (default 0)     | batch.size가 도달하지 않으면 메세지를 보내지 않기 때문에 마냥 기다릴 수는 없어 해당 시간을 설정하여 size가 도달하지 않더라도 시간이 초과하면 메세지를 보내게 된다. |

7. `Sender`를 통해 I/O Thread에서 주기적으로 `Accumulator`의 메시지들을 Kafka로 전송
8. 만약, 전송이 실패됐다면 Retry(재전송)을 진행
9. 만약, Retry가 반복된다면 throw Exception 진행

</br>

---

</br>

## 5. Partitioner

> - Topic의 메시지를 어떤 Partition으로 보낼지 결정하는 알고리즘
> - Key의 존재 여부에 따라 알고리즘이 다름
> - `Customizing` 가능

</br>

### 1) Key가 Null이 아닐 때의 Default Partitioner

</br>

![Key가 Null이 아닐 때의 Default Partitioner](../img/part1/04_05_Default_Partitioner_Not_null.PNG "Key가 Null이 아닐 때의 Default Partitioner")

- `Key`값이 Null 아닐 때의 `Default Partitioner` 알고리즘은 `Key` 값의 `Hashing` 및 `modular` 연산을 통해 어떤 `Partition`으로 보낼지 결정

</br>

### 2) Key가 Null일 때의 Default Partitioner (Sticky Partitioner)

</br>

![Key가 Null일 때의 Default Partitioner](../img/part1/04_06_Default_Partitioner_null.PNG "Key가 Null일 때의 Default Partitioner")

- `Key`가 `Null`일 때의 경우 Default Partitioner는 Kafka 2.4 전후로 나뉜다.
  - Kafka 2.4 이전 : _`Round Robin`_ 방식
  - Kafka 2.4 이후 : _`Sticky Partitioner`_ 방식
  - 알고리즘이 바뀐 이유 : Batch 형태의 메시지를 보낼 때 메시지가 다 담겨지기 전에 보내지는 현상이 있어 Kafka 2.4 이후부턴 Batch가 다 담겨질 때까지 Partition을 채운 후 전송한다.
  - 장점
    - 효율적인 Resource 사용
    - Kafka로 보내는 `Request(Network I/O)`를 줄일 수 있기에 Broker 입장에서 처리량이 줄어든다.
  - 참고: [https://www.confluent.io/blog/apache-kafka-producer-improvements-sticky-partitioner/]
- Producer는 Partition에 Data를 전송하기 전에 Accumulator에 Data를 Buffer로 쌓은 후 발송
